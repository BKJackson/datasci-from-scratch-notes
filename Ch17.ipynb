{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 17: Decision Trees\n",
    "Notes on \"Data Science from Scratch\" by Joel Grus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is a Decision Tree?\n",
    "- uses a tree structure to represent a number of possible *decision paths* and an outcome for each path\n",
    "- easy to understand and interpret, and the process by which they reach a prediction is transparent\n",
    "- can easily handle a mix of numeric and categorical attributes\n",
    "- can classify data for which attributes are missing\n",
    "- finding an \"optimal\" tree for a set of training data is computationally a very hard problem\n",
    "- it's very easy (and bad) to build decision trees that are *overfitted* to the training data (that don't generalize well to unseen daya)\n",
    "\n",
    "Can be divided into two types:\n",
    "- *classification trees* - produce categorical outputs\n",
    "- *regression trees* - produce numeric outputs\n",
    "\n",
    "Specifically, we'll look at the **ID3 algorithm** for learning a decision tree from a set of labeled data and restrict ourselves to binary outputs (e.g., Yes/No) instead of 3 or more (e.g., Yes/Maybe/No)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "To build a decision tree we need to decide what questions to ask and in what order.\n",
    "\n",
    "We want to choose questions whose answers give a lot of information about what our tree should predict.  We capture \"how much information\" with *entropy*, or amount of uncertainty associated with data.  \n",
    "\n",
    "Imagine we have a set $S$ of data, each member of which is labeled as belonging to one of a finite number of classes $C_1, ..., C_n$. \n",
    "- If all the data points belong to a single class then entropy (amount of uncertainty) should be low.\n",
    "- If the data points are evenly spread across the class then entropy should be high.\n",
    "\n",
    "Let $p_i$ be the proportion of data labeled as class $c_i$.  Entropy is defined as:\n",
    "$$H(S) = -p_1 \\log_2 p_1 - ... - p_n \\log_2 p_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112721610>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11244cf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(0.05, 1.0, 0.05)\n",
    "ys = -xs * np.log2(xs)\n",
    "mpl.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we see that the entropy would be very small when every $p_i$ is close to $0$ or $1$ (when most of the data is in a single class) and would be larger when many of the $p_i$'s are not close to $0$ or $1$ (when data is spread across multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    \"\"\"Give a list of class probabilities, compute the entropy.\"\"\"\n",
    "    return sum(-p * math.log(p, 2)\n",
    "               for p in class_probabilitiers\n",
    "               if p) # ignore zero probabilities\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "           for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Entropy of a Partitition\n",
    "The stuff above computes the entropy (\"uncertainty\") of a single set of labeled data.  Now we want to get an idea of the entropy that results from partitioning a set of data in a certain way.  We want the partition to have low entropy if it splits the data into subsets that themselves have low entropy (high certainty), and high entropy if it contains subsets that have high entropy (low certainty).\n",
    "\n",
    "If we partition our data $S$ into subsets $S_1, ..., S_m$ containing proportions $q_1, ..., q_m$ of the data, the the entropy of partition is the weighted sum:\n",
    "$$H = q_1 H(S_1) + ... + q_m H(S_m)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    \"\"\"Find the entropy from this partition of data into subsets.\n",
    "    Subsets is a list of lists of labeled data.\"\"\"\n",
    "    \n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum( data_entropy(subset) * len(subset) / total_count\n",
    "              for subset in subsets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- 1.0 * np.log2(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'},   False),\n",
    "    ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yse'},   False),\n",
    "    ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'},   True),\n",
    "    ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'},   True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3 Algorithm\n",
    "- If the data all have the same label, then create a leaf node that predicts that label and then stop.\n",
    "- If the list of attributes is empty (i.e., there are no more possible questions to ask), then create a leaf node that predicts the most common label and then stop.\n",
    "- Otherwise, try partitioning the data by each of the attributes.\n",
    "- Choose the partition with the lowest partition entropy.\n",
    "- Add a decision node based on the chosed attribute.\n",
    "- Recur on each partitioned subset using the remaining attributes.\n",
    "\n",
    "This is known as a \"greedy\" algorithm because at each step it chooses the most immediately best option.  Give a data set, there may be a better tree with a worse-looking first move.  If so, this algorithm won't find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
